{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "train = pd.read_csv('/home/mw/input/pre8881/train.csv')\n",
    "test = pd.read_csv('/home/mw/input/pretest_a3048/test_a.csv')\n",
    "all_df = pd.concat([train,test], sort=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理缺失值和异常值，以及将obeject类型转换为数值类型\n",
    "\n",
    "# #异常值\n",
    "# all_df.loc[all_df['p1_prior_days_to_insure']>90, 'p1_prior_days_to_insure'] = 90 #提前签单时间最大不超过90天\n",
    "# all_df.loc[all_df['nprem_ly']<0, 'nprem_ly'] = 0 #保费不能小于0\n",
    "\n",
    "# # 通过出险次数填充ncd中的缺失值\n",
    "# tmp_df = all_df.groupby('clmnum')['ncd_ly'].agg({'ncd_mean':'mean'})\n",
    "# for i in range(9):\n",
    "#     all_df.loc[(all_df['clmnum']==i)&(all_df['ncd_ly'].isna()),'ncd_ly'] = tmp_df.loc[i, 'ncd_mean']\n",
    "\n",
    "#object转数值型\n",
    "disordered_feats = ['xz', 'change_owner', 'p1_gender', 'p2_marital_status', 'f1_child_flag',\n",
    "            'f2_posses_house_flag', 'w1_pc_wx_use_flag','p1_is_bank_eff', 'p2_is_enterprise_owner',\n",
    "            'p2_is_smeowner', 'p2_is_child_under_15_family', 'p2_is_adult_over_55_family',\n",
    "            'p1_census_register']\n",
    "lb = LabelEncoder()\n",
    "for f in disordered_feats:\n",
    "    # print(np.array(all_df[f]))\n",
    "    # all_df[f].fillna(all_df[f].mode()[0], inplace=True)\n",
    "    all_df[f] = lb.fit_transform(np.array(all_df[f]).astype(str).reshape(-1,1))\n",
    "\n",
    "#有序object属性\n",
    "all_df['p2_client_grade'] = all_df['p2_client_grade'].str[6:8]\n",
    "all_df['p2_client_grade'].replace({'黄铜':0, '白银':1, '黄金':2, '铂金':3, '钻石':4, '黑钻':5}, inplace=True)\n",
    "all_df['xb'].replace({'主全':0, '交三':1, '单交':2, '损三':3, '单三':4, '其他':5, '交损':6}, inplace=True)\n",
    "\n",
    "index = ~(all_df['birth_month'].isna())\n",
    "all_df.loc[index,'birth_month'] = all_df.loc[index,'birth_month'].apply(lambda x: int(re.findall('[0-9]+', str(x))[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_type(x):\n",
    "    if '轿车' in x:\n",
    "        return '轿车'\n",
    "    elif '校车' in x:\n",
    "        return '校车'\n",
    "    elif ('多用途乘用车' in x) or ('商务车' in x) or ('休旅车' in x) or ('多功能乘用车' in x) or ('插电式混合动力多用途乘' in x):\n",
    "        return '多用途乘用车'\n",
    "    elif '客车' in x:\n",
    "        return '客车'\n",
    "    elif '越野车' in x:\n",
    "        return '越野车'\n",
    "    elif '运动型乘用车' in x:\n",
    "        return '运动型乘用车'\n",
    "    elif '旅行车' in x:\n",
    "        return '旅行车'\n",
    "    elif ('纯电动乘用车' in x) or ('短头乘用车' in x) or ('轻型越野汽车' in x) or ('越野乘用车' in x):\n",
    "        return '乘用车'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#高基数类别特征 频率编码\n",
    "for f in ['trademark_cn', 'dpt', 'brand_cn', 'make_cn', 'series', 'client_no']:\n",
    "    all_df[f+'_freq'] = all_df[f].map(all_df[f].value_counts())\n",
    "\n",
    "# 提取车型，并合并数量较少的一些车型\n",
    "all_df['car_type'] = all_df['make_cn'].apply(lambda x: re.split('[a-z0-9A-Z]+[\\)\\-\\Ⅲ\\Ⅱ\\s]*', x)[-1])\n",
    "all_df.replace('', '无', inplace=True)\n",
    "all_df['car_type'] = all_df['car_type'].apply(lambda x: get_car_type(x))\n",
    "index = all_df['car_type'].isin(['工程车','无', '流动服务车', '宣传车', '旅居车', '校车', '囚车', '轻型汽车',\n",
    "                        '伤残运送车', '服务车', '检测车', '救护车', '多功能商旅车', '教练车', '双排座货车'])\n",
    "all_df.loc[index, 'car_type'] = '其他'\n",
    "\n",
    "# 车品牌和车型组合，车型和车系组合\n",
    "all_df['trademark_cartype'] = all_df['trademark_cn'] + '_' +all_df['car_type']\n",
    "all_df['series'].fillna('无')\n",
    "all_df['trademark_series'] = all_df['trademark_cn'] + '_' +all_df['series'].fillna('无')\n",
    "\n",
    "lb = LabelEncoder()\n",
    "#Label Encode\n",
    "lb_feats = ['dpt', 'car_type','trademark_cartype', 'trademark_series','trademark_cn']\n",
    "for f in lb_feats:\n",
    "    all_df[f] = lb.fit_transform(np.array(all_df[f]).astype(str).reshape(-1,1))\n",
    "\n",
    "# 家庭中是否同时15岁以下的和55岁以上\n",
    "# all_df['family_15_55'] = all_df['p2_is_adult_over_55_family'] + all_df['p2_is_child_under_15_family']\n",
    "\n",
    "# 可提取初登日期至今的一个时间（天数），可以得到汽车的年限时间\n",
    "from datetime import datetime\n",
    "now = datetime(2021,1,31)\n",
    "all_df['regdate'] = all_df['regdate'].apply(lambda x: x.split(' ')[0])\n",
    "all_df['regdate'] = pd.to_datetime(all_df['regdate'], format='%Y-%m-%d')\n",
    "all_df['regdate_to_now_month'] = (now-all_df['regdate']).dt.days/30\n",
    "all_df['regdate_to_now_month'] = all_df['regdate_to_now_month'].apply(lambda x:np.ceil(x))\n",
    "\n",
    "# # 车险提供服务和使用服务的差值\n",
    "# all_df['service_diff'] = all_df['p1_service_offer_cnt']-all_df['p3_service_use_cnt']\n",
    "\n",
    "# 各种车险保费和保额的总额\n",
    "all_df['nprem_total'] = all_df[['nprem_od','nprem_tp','nprem_bt','nprem_vld','nprem_vlp']].sum(axis=1)\n",
    "all_df['si_total'] = all_df[['si_od','si_tp','si_bt','si_vld','si_vlp']].sum(axis=1)\n",
    "\n",
    "# 根据近五年的随车非车保费、保额提取，近五年的均值、方差、以及变化趋势（递增、递减、还是有增有减）,以及每年变化的方差和均值\n",
    "feats = ['suiche_nonauto_nprem_20','suiche_nonauto_nprem_19','suiche_nonauto_nprem_18',\n",
    "            'suiche_nonauto_nprem_17','suiche_nonauto_nprem_16','suiche_nonauto_amount_20',\n",
    "            'suiche_nonauto_amount_19','suiche_nonauto_amount_18','suiche_nonauto_amount_17',\n",
    "            'suiche_nonauto_amount_16']\n",
    "nprem_feats = ['suiche_nonauto_nprem_20','suiche_nonauto_nprem_19','suiche_nonauto_nprem_18',\n",
    "                'suiche_nonauto_nprem_17','suiche_nonauto_nprem_16']\n",
    "amount_feats = ['suiche_nonauto_amount_20','suiche_nonauto_amount_19','suiche_nonauto_amount_18',\n",
    "                'suiche_nonauto_amount_17','suiche_nonauto_amount_16']\n",
    "def isIncrease(arr):\n",
    "    arr_diff = np.diff(arr)\n",
    "    if len(np.where(arr_diff==0)[0]) == len(arr_diff):\n",
    "        return 0\n",
    "    if len(np.where(arr_diff<=0)[0]) == len(arr_diff):\n",
    "        return 2 #递增\n",
    "    elif len(np.where(arr_diff>=0)[0]) == len(arr_diff):\n",
    "        return 1 #递减\n",
    "    else:\n",
    "        return 0 #有增有减\n",
    "# all_df['suiche_nonauto_nprem_mean_last5year'] = all_df[feats[:5]].mean(axis=1)\n",
    "# all_df['suiche_nonauto_nprem_std_last5year'] = all_df[feats[:5]].std(axis=1)\n",
    "# all_df['suiche_nonauto_amount_mean_last5year'] = all_df[feats[5:]].mean(axis=1)\n",
    "# all_df['suiche_nonauto_amount_std_last5year'] = all_df[feats[5:]].std(axis=1)\n",
    "# all_df['suiche_nonauto_nprem_diff_mean_last5year'] = -np.diff(all_df[feats[:5]], axis=1).mean(axis=1)\n",
    "# all_df['suiche_nonauto_nprem_diff_std_last5year'] = -np.diff(all_df[feats[:5]], axis=1).std(axis=1)\n",
    "# all_df['suiche_nonauto_amount_diff_mean_last5year'] = -np.diff(all_df[feats[5:]], axis=1).mean(axis=1)\n",
    "# all_df['suiche_nonauto_amount_diff_std_last5year'] = -np.diff(all_df[feats[5:]], axis=1).std(axis=1)\n",
    "all_df['suiche_nonauto_nprem_trend_last5year'] = all_df[feats[:5]].apply(lambda x : isIncrease([x[f] for f in feats[:5]]), axis=1)\n",
    "all_df['suiche_nonauto_amount_trend_last5year'] = all_df[feats[5:]].apply(lambda x : isIncrease([x[f] for f in feats[5:]]), axis=1)\n",
    "all_df['suiche_nonauto_nprem_amount_ratio_20'] = all_df['suiche_nonauto_nprem_20'] / all_df['suiche_nonauto_amount_20']\n",
    "all_df['suiche_nonauto_nprem_amount_ratio_19'] = all_df['suiche_nonauto_nprem_19'] / all_df['suiche_nonauto_amount_19']\n",
    "all_df['suiche_nonauto_nprem_amount_ratio_20'].fillna(0, inplace=True)\n",
    "all_df['suiche_nonauto_nprem_amount_ratio_19'].fillna(0, inplace=True)\n",
    "\n",
    "# 近五年随车非车保费的差值\n",
    "for i in range(len(nprem_feats[:3])-1):\n",
    "    y1 = nprem_feats[i].split('_')[3]\n",
    "    y2 = nprem_feats[i+1].split('_')[3]\n",
    "    all_df['nprem_diff_'+y1+'_'+y2] = all_df[nprem_feats[i]] - all_df[nprem_feats[i+1]]\n",
    "# all_df['nprem_diff_20_18'] = all_df['suiche_nonauto_nprem_20'] - all_df['suiche_nonauto_nprem_18']\n",
    "\n",
    "# for i in range(len(amount_feats[:3])-1):\n",
    "#     y1 = amount_feats[i].split('_')[3]\n",
    "#     y2 = amount_feats[i+1].split('_')[3]\n",
    "#     all_df['amount_diff_'+y1+'_'+y2] = all_df[amount_feats[i]] - all_df[amount_feats[i+1]]\n",
    "# all_df['amount_diff_20_18'] = all_df['suiche_nonauto_amount_20'] - all_df['suiche_nonauto_amount_18']\n",
    "\n",
    "# 线下提升微弱，线上A榜有所下降\n",
    "# all_df['suiche_nonauto_nprem_amount_ratio_17'] = all_df['suiche_nonauto_nprem_17'] / all_df['suiche_nonauto_amount_17']\n",
    "# all_df['suiche_nonauto_nprem_amount_ratio_16'] = all_df['suiche_nonauto_nprem_16'] / all_df['suiche_nonauto_amount_16']\n",
    "# all_df['suiche_nonauto_nprem_amount_ratio_17'].fillna(0, inplace=True)\n",
    "# all_df['suiche_nonauto_nprem_amount_ratio_16'].fillna(0, inplace=True)\n",
    "\n",
    "# all_df['suiche_nonauto_nprem_total_ly5'] = all_df[nprem_feats].sum(axis=1) #近五年非车险保费总额\n",
    "# all_df['suiche_nonauto_amount_total_ly5'] = all_df[amount_feats[:3]].sum(axis=1) #近五年非车险保额总额\n",
    "\n",
    "# 构造保费和保额之间的关系\n",
    "all_df['nprem_si_ratio'] = all_df['nprem_total'] / all_df['si_total']\n",
    "all_df['si_nprem_ratio'] = all_df['si_total'] / all_df['nprem_total']\n",
    "all_df['nprem_total_nprem_ly_diff'] = all_df['nprem_ly'] - all_df['nprem_total']\n",
    "all_df.loc[all_df['si_nprem_ratio']==np.inf, 'si_nprem_ratio'] = np.nan\n",
    "all_df['nprem_si_ratio'].fillna(0, inplace=True)\n",
    "all_df['si_nprem_ratio'].fillna(0, inplace=True)\n",
    "\n",
    "# nprem_feats = ['nprem_od','nprem_tp','nprem_bt','nprem_vld','nprem_vlp']\n",
    "# si_feats = ['si_od','si_tp','si_bt','si_vld','si_vlp']\n",
    "# for f1, f2 in zip(nprem_feats, si_feats):\n",
    "#     # all_df[f1+'_'+f2+'_ratio'] = all_df[f1] / all_df[f2]\n",
    "#     all_df[f2+'_'+f1+'_ratio'] = all_df[f2] / all_df[f1]\n",
    "#     # all_df.loc[all_df[f1+'_'+f2+'_ratio']==np.inf, f1+'_'+f2+'_ratio'] = np.nan\n",
    "#     all_df.loc[all_df[f2+'_'+f1+'_ratio']==np.inf, f2+'_'+f1+'_ratio'] = np.nan\n",
    "\n",
    "# ncd和保费的乘积\n",
    "# all_df['ncd_mult_nprem_ly'] = all_df['ncd_ly'] * all_df['nprem_ly']\n",
    "all_df['ncd_mult_nprem_od'] = all_df['ncd_ly'] * all_df['nprem_od']\n",
    "all_df['ncd_mult_nprem_tp'] = all_df['ncd_ly'] * all_df['nprem_tp']\n",
    "all_df['ncd_mult_nprem_bt'] = all_df['ncd_ly'] * all_df['nprem_bt']\n",
    "all_df['ncd_mult_nprem_vld'] = all_df['ncd_ly'] * all_df['nprem_vld']\n",
    "all_df['ncd_mult_nprem_vlp'] = all_df['ncd_ly'] * all_df['nprem_vlp']\n",
    "# all_df['ncd_mult_nprem_total'] = all_df['ncd_ly'] * all_df['nprem_total']\n",
    "\n",
    "# 新车购置价和保费之间的关系\n",
    "all_df['newvalue_nprem_ly_ratio'] = all_df['newvalue'] / all_df['nprem_ly']\n",
    "all_df.loc[all_df['newvalue_nprem_ly_ratio']==np.inf, 'newvalue_nprem_ly_ratio'] = np.nan\n",
    "all_df['newvalue_si_od_ratio'] = all_df['newvalue'] / all_df['si_od']\n",
    "all_df.loc[all_df['newvalue_si_od_ratio']==np.inf, 'newvalue_si_od_ratio'] = np.nan\n",
    "all_df['newvalue_si_bt_ratio'] = all_df['newvalue'] / all_df['si_bt']\n",
    "all_df.loc[all_df['newvalue_si_bt_ratio']==np.inf, 'newvalue_si_bt_ratio'] = np.nan\n",
    "\n",
    "# # 新车购置价和车辆登记年限的关系\n",
    "# all_df['newvalue_regdate_ratio'] = all_df['newvalue'] / all_df['regdate_to_now_month']\n",
    "\n",
    "# all_df['nprem_ly_newvalue_ratio'] = all_df['nprem_ly'] / all_df['newvalue'] #上年保费\n",
    "# all_df.loc[all_df['nprem_ly_newvalue_ratio']==np.inf, 'nprem_ly_newvalue_ratio'] = np.nan\n",
    "# all_df['si_od_newvalue_ratio'] = all_df['si_od'] / all_df['newvalue'] #车损险\n",
    "# # all_df.loc[all_df['newvalue_si_od_ratio']==np.inf, 'newvalue_si_od_ratio'] = np.nan\n",
    "# all_df['si_bt_newvalue_ratio'] = all_df['si_bt'] / all_df['newvalue'] #盗抢险\n",
    "\n",
    "# # 构造车价和房价的关系\n",
    "# all_df['newvalue_houseprice_ratio'] = all_df['newvalue'] / all_df['f2_cust_housing_price_total']\n",
    "# all_df.loc[all_df['newvalue_houseprice_ratio']==np.inf,'newvalue_houseprice_ratio'] = np.nan\n",
    "# all_df['houseprice_newvalue_ratio'] = all_df['f2_cust_housing_price_total'] / all_df['newvalue']\n",
    "# all_df['house_car_value'] = all_df['f2_cust_housing_price_total'] + all_df['newvalue']\n",
    "\n",
    "# # 车险出现次数和非车险出现次数\n",
    "# all_df['clmnum_num_notcar_claim_ratio'] = all_df['clmnum'] / all_df['num_notcar_claim']\n",
    "\n",
    "# # 点击非车险时长\n",
    "# all_df['dur_personal_insurance_90_seconds'] = all_df['dur_personal_insurance_90'] / 1000\n",
    "# all_df['dur_personal_insurance_90_minutes'] = all_df['dur_personal_insurance_90'] / (1000*60)\n",
    "\n",
    "# # 车险积分和保费之间的交叉\n",
    "# all_df['score_nprem_ly_ratio'] = all_df['service_score_available'] / all_df['nprem_ly']\n",
    "# all_df.loc[all_df['score_nprem_ly_ratio']==np.inf, 'score_nprem_ly_ratio'] = np.nan\n",
    "# all_df['score_nprem_total_ratio'] = all_df['service_score_available'] / all_df['nprem_total']\n",
    "# all_df.loc[all_df['score_nprem_total_ratio']==np.inf, 'score_nprem_total_ratio'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.drop(['client_no', 'regdate', 'use_type', 'brand_cn', 'make_cn', 'series'\n",
    "            ], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#节省内存\n",
    "def reduce_mem_usage(df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2 \n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2 \n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = reduce_mem_usage(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = all_df[~all_df['y1_is_purchase'].isna()]\n",
    "test_df = all_df[all_df['y1_is_purchase'].isna()]\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import catboost as cab\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_train(name, X_data, Y_data, test, cat_features=[], model=None, random_state=1023):\n",
    "    # 交叉验证\n",
    "    folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "    preds_test_mean = np.zeros(len(test))\n",
    "    mean_train_auc, mean_val_auc = 0.0, 0.0\n",
    "    oof = np.zeros(len(Y_data))\n",
    "    for i, (train_index, val_index) in enumerate(folds.split(X_data, Y_data)):\n",
    "        print('fold ', i)\n",
    "        X_data_train = X_data.iloc[train_index]\n",
    "        Y_data_train = Y_data.iloc[train_index]\n",
    "        X_data_val = X_data.iloc[val_index]\n",
    "        Y_data_val = Y_data.iloc[val_index]\n",
    "\n",
    "        if name == 'lgb':\n",
    "            clf = lgb.LGBMClassifier(num_leaves=63, min_child_samples=2, learning_rate=0.02,\n",
    "                                    n_estimators=10000, n_jobs=2, random_state=random_state,\n",
    "                                     subsample=0.8, colsample_bytree=0.8, objective='binary'\n",
    "                                     # tree_learner='serial',\n",
    "                                     )\n",
    "            clf.fit(X_data_train, Y_data_train, eval_set=[(X_data_val, Y_data_val)],\n",
    "                      categorical_feature=cat_features,\n",
    "                      eval_metric='AUC',\n",
    "                      early_stopping_rounds=200,\n",
    "                      verbose=50)\n",
    "        elif name == 'cab':\n",
    "            X_data_train[cat_features] = X_data_train[cat_features].astype(int)\n",
    "            X_data_val[cat_features] = X_data_val[cat_features].astype(int)\n",
    "            clf = cab.CatBoostClassifier(iterations=2000\n",
    "                              ,learning_rate=0.05\n",
    "                              ,depth=7\n",
    "                              ,silent=True\n",
    "                              ,thread_count=4\n",
    "                              ,task_type='CPU'\n",
    "                              ,cat_features=cat_features,\n",
    "                                eval_metric='AUC',\n",
    "                                random_seed=1023\n",
    "                              )\n",
    "            clf.fit(X_data_train, Y_data_train, eval_set=[(X_data_val, Y_data_val)],verbose=200,\n",
    "                                         early_stopping_rounds=200)\n",
    "            test[cat_features] = test[cat_features].astype(int)\n",
    "        elif name == 'xgb':\n",
    "            clf = xgb.XGBClassifier(max_depth=6\n",
    "                      ,learning_rate=0.1\n",
    "                      ,n_estimators=10000\n",
    "                      ,reg_alpha=0.005\n",
    "                      ,n_jobs=4\n",
    "                      ,importance_type='total_cover'\n",
    "                     )\n",
    "            clf.fit(X_data_train, Y_data_train, eval_set=[(X_data_val, Y_data_val)],\n",
    "                    early_stopping_rounds=100,verbose=False)\n",
    "        else:\n",
    "            clf = model\n",
    "            clf.fit(X_data_train, Y_data_train)\n",
    "        # 训练集\n",
    "        y_pred_train = clf.predict_proba(X_data_train)[:,1]\n",
    "        auc_train = roc_auc_score(Y_data_train, y_pred_train)\n",
    "        \n",
    "        mean_train_auc += auc_train\n",
    "        print('train auc: {}'.format(auc_train))\n",
    "        # 验证集\n",
    "        y_pred_val = clf.predict_proba(X_data_val)[:,1]\n",
    "        auc_val = roc_auc_score(Y_data_val, y_pred_val)\n",
    "        mean_val_auc += auc_val\n",
    "        print('val auc: {}'.format(auc_val))\n",
    "\n",
    "        oof[val_index] += y_pred_val\n",
    "\n",
    "        y_pred_test = clf.predict_proba(test)[:,1]\n",
    "        preds_test_mean += y_pred_test/folds.n_splits\n",
    "        print()\n",
    "\n",
    "    print('*'*80)\n",
    "    print('train mean auc: {}'.format(mean_train_auc/folds.n_splits))\n",
    "    print('val mean auc: {} | oof auc: {}'.format(mean_val_auc/folds.n_splits, roc_auc_score(Y_data, oof)))\n",
    "\n",
    "    return preds_test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('/home/mw/work/train_processed.csv')\n",
    "# test_df = pd.read_csv('/home/mw/work/test_processed.csv')\n",
    "\n",
    "#nprem_si_ratio si_nprem_ratio nprem_total_nprem_ly_diff\n",
    "train_features = [f for f in train_df.columns if f not in ['y1_is_purchase',  'carid', 'client_no']] \n",
    "cat_features = ['dpt','xz','xb','change_owner','p1_gender','p1_census_register','p2_marital_status',\n",
    "                'f1_child_flag','f2_posses_house_flag','w1_pc_wx_use_flag','p1_is_bank_eff', \n",
    "                'p2_is_enterprise_owner','p2_is_smeowner','p2_is_child_under_15_family',\n",
    "                'p2_is_adult_over_55_family',\n",
    "                ]\n",
    "pred_test = cv_train('lgb', train_df.loc[:, train_features], train_df.loc[:, 'y1_is_purchase'],\n",
    "                    test_df.loc[:, train_features],cat_features=[])\n",
    "# train.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
